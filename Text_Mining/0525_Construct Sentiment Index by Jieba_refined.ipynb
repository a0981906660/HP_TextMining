{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情緒分析 with Jieba\n",
    "\n",
    "1. raw data是「月資料」的新聞，在`\"raw/unique\"`下\n",
    "\n",
    "2. import林的情緒字典、NTUSD的情緒字典\n",
    "\n",
    "3. a. 先用jieba斷詞並直接建立情緒指標\n",
    "\n",
    "   b. 使用CKIP斷詞並建立情緒指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import os\n",
    "import glob\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先整理檔案\n",
    "\n",
    "# Other Task:將取過`set()`的每月新聞月資料存下來"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先產生每個日期的lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n"
     ]
    }
   ],
   "source": [
    "#建立yyyy/mm/dd的list\n",
    "    #month:我要二月份是02而不是2\n",
    "mon_2d = [\"%.2d\" % i for i in range(1, 13)]\n",
    "print(mon_2d)\n",
    "\n",
    "day_2d = [\"%.2d\" % i for i in range(1, 32)]\n",
    "print(mon_2d)\n",
    "\n",
    "#用來在if判斷是否是某月新聞的 month list\n",
    "date_lst = []\n",
    "\n",
    "for year in range(1999, 2018+1):\n",
    "    for month in mon_2d:\n",
    "        for day in day_2d:\n",
    "            #exec(f\"m{month}y{year} = []\")\n",
    "            date_lst.append(f\"{year}/{month}/{day}\")\n",
    "            date_lst.append(f\"{year}-{month}-{day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1999/01/01',\n",
       " '1999-01-01',\n",
       " '1999/01/02',\n",
       " '1999-01-02',\n",
       " '1999/01/03',\n",
       " '1999-01-03',\n",
       " '1999/01/04',\n",
       " '1999-01-04',\n",
       " '1999/01/05',\n",
       " '1999-01-05']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_lst[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理檔案：將一個一個月的新聞取unique，且找出日期，並按照日期排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存單一一個月的新聞\n",
    "month_dict = {}\n",
    "#Overall Dictionary that saves all news of all months\n",
    "text_dict = {}\n",
    "\n",
    "for filepath in glob.iglob('raw/*.csv'):\n",
    "    #print(filepath)\n",
    "    #讀檔\n",
    "    sampleData = pd.read_csv(filepath)\n",
    "    #建立set\n",
    "    news_text = set()\n",
    "    #一個個加進set裡\n",
    "    for i in range(0, len(sampleData)):\n",
    "        news_text.add(sampleData.iloc[i][0])\n",
    "    #將set變回list\n",
    "    news_text = list(news_text)\n",
    "    \n",
    "    #拿key name，從檔名來\n",
    "    keyname = filepath.split(sep = '/')[1].split(sep = '.')[0]\n",
    "    \n",
    "    ############寫一個功能把檔存回csv############\n",
    "    output_df = pd.DataFrame()\n",
    "    date_count = 1\n",
    "    for txt in news_text: #在一個月裡面的每一則新聞跑\n",
    "        for dat in date_lst: #讓這則新聞在「日」的日期裡跑，找出日期\n",
    "            if dat in txt:   #找到對應的日期\n",
    "                output_df[dat+\"_\"+str(date_count)] = [txt] #讓該月的dataframe新增一個col來裝一則新聞，但同一天會有數則新聞\n",
    "                date_count+=1\n",
    "\n",
    "    output_df = output_df.transpose()  #取transpose\n",
    "    output_df = output_df.sort_index(axis = 0) #按照日期排序row\n",
    "    \n",
    "    #colnam = dat[:-6]+\"-\"+dat[-5:-3] #把要拿來當col nam的日期格式寫成 \"2001-02\"\n",
    "    output_df.columns = [keyname]\n",
    "    #output_df[\"Date\"] = output_df.index\n",
    "    \n",
    "    #調換兩個column\n",
    "    #columns_titles = [\"Date\",colnam]\n",
    "    #output_df=output_df.reindex(columns=columns_titles)\n",
    "    \n",
    "    #存這個月的csv\n",
    "    outpath = \"raw/unique/\"+keyname+\".csv\"\n",
    "    output_df.to_csv(outpath)\n",
    "    \n",
    "    overall_output_df = output_df\n",
    "    \n",
    "    #將當前月份的新聞list當作value放進dictionary裡\n",
    "    text_dict[keyname] = news_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 存下字典\n",
    "\n",
    "* ref: https://kite.com/python/answers/how-to-save-a-dictionary-to-a-file-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"raw/unique/dict/AllNewsDictionary.pkl\", \"wb\")\n",
    "pickle.dump(text_dict, a_file, pickle.HIGHEST_PROTOCOL)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 或用Numpy存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "np.save(\"raw/unique/dict/AllNewsDictionary_np\", text_dict)\n",
    "\n",
    "# Load\n",
    "#read_dictionary = np.load('my_file.npy',allow_pickle='TRUE').item()\n",
    "#print(read_dictionary['hello']) # displays \"world\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: `text_dict{}` 是我們所有新聞的字典\n",
    "\n",
    "#### 以上：Other Taks Ended\n",
    "\n",
    "#### 以下：建立情緒字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Sentiment Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_table = pd.read_excel('NTUSD/NTUSD+Lin_dict.xlsx',sheet_name='Positive')\n",
    "neg_table = pd.read_excel('NTUSD/NTUSD+Lin_dict.xlsx',sheet_name='Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#寫成字典\n",
    "pos_dict = dict(zip(pos_table.pos_word, pos_table.score))\n",
    "neg_dict = dict(zip(neg_table.neg_word, neg_table.score))\n",
    "sentiment_dict={**pos_dict,**neg_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words = []\n",
    "f = open(\"NTUSD/stopwords_ch.txt\", \"r\")\n",
    "#stop_words = f.readlines() #會讀進分行符號\\n\n",
    "stop_words = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach\n",
    "\n",
    "簡單找出情緒字典，並給定符號方向，最後簡單加總"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def\n",
    "#句子到詞彙：sentence to word\n",
    "def sent2word(sentence,stop_words=stop_words):\n",
    "    words = jieba.cut(sentence, HMM=False)\n",
    "    words = [w for w in words if w not in stop_words] #不在停用字當中的才留下 i.e.去掉無意義的短小字\n",
    "    return words\n",
    "\n",
    "def get_sentiment(sent):\n",
    "    tokens = sent2word(sent)\n",
    "    score = 0\n",
    "    countword = 0\n",
    "    for w in tokens:\n",
    "        if w in sentiment_dict.keys():\n",
    "            score += sentiment_dict[w]\n",
    "            countword += 1\n",
    "    if countword != 0:\n",
    "        return score/countword\n",
    "    else:\n",
    "        return 0\n",
    "##每則新聞的情緒指數按照「情緒字出現的頻率」除以「該則新聞的詞彙數」得到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/s9/20ywlbts5j1473c15zd3vgqw0000gn/T/jieba.cache\n",
      "Loading model cost 1.296 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17647058823529413"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext=\"行政院長蕭萬長面對垂危的營建業、銷售率節節下滑的房市、逾放比率偏高的銀行業，決定釋出1,500億元郵儲金全力挽救營建業，希望用霹靂的手段，怏速救房市；下藥很猛，可保命不死，但難免衍生一堆後遺症。上周台灣省建築投資公會、高雄地區營建上市公司等營建業分別向總統李登輝、蕭萬長大吐苦水，終於在中央銀行、財政部聯手下，短短幾天即祭出強心針，營建業對於政府的回應多額手稱慶，表示政策利多一定有效果。促成這項大政策的民間建築業者，並非台灣省建商公會或高雄建商，而是中華民國建築投資公會全聯會理事長利堉璘。林堉璘說：「不是要政府救業者，而是要挽回大眾購屋信心。」行政院強力釋金救房市，用的是全民稅收力量，指定的用途是買新屋，明顯是為建商解套，也為銀行解除危機，並預估消化10萬戶餘屋。政府應該注意的是，政策利多雖可產生一定效益，但是人為干預嚴重扭曲房市機制，可能波及中古屋市場，也可能因房價再跌，反使民眾套牢。台灣房市最大危機靈在經濟力降低，民眾購屋能力不足，營建業財務危機四伏，民眾購屋信心崩潰，利多政策有助提升房市景氣，但最怕的是，政府的籌碼一次用光後，如果效益不彰，可能出現更大的風暴。\"\n",
    "get_sentiment(testtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Index for all months between 1999-01 to 2018-02\n",
    "\n",
    "1. 對每個月的資料都取set\n",
    "\n",
    "2. 存成dictionary，key是年月份，value是一個list；list裡面是該月份的新聞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Overall Dictionary that saves all news of all months\n",
    "text_dict = {}\n",
    "\n",
    "for filepath in glob.iglob('raw/*.csv'):\n",
    "    #print(filepath)\n",
    "    #讀檔\n",
    "    sampleData = pd.read_csv(filepath)\n",
    "    #建立set\n",
    "    news_text = set()\n",
    "    #一個個加進set裡\n",
    "    for i in range(0, len(sampleData)):\n",
    "        news_text.add(sampleData.iloc[i][0])\n",
    "    #將set變回list\n",
    "    news_text = list(news_text)\n",
    "    \n",
    "    #拿key name，從檔名來\n",
    "    keyname = filepath.split(sep = '/')[1].split(sep = '.')[0]\n",
    "    \n",
    "    #將當前月份的新聞list當作value放進dictionary裡\n",
    "    text_dict[keyname] = news_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008/03/04- [工商/理財趨勢/C1版] \\n\\n\\n二月自住型房客回籠 價量齊揚 房市回春 北市每坪均價30.4萬\\n\\n\\n                【許（清爭）文】\\u3000\\u3000農曆年後在台股回升、政策利多釋出、以及通膨刺激置產意願等三大動力之下，自住型房客回籠，買氣增溫，房仲業者表示，尤其是台北縣及高雄市，房價明顯上揚漲最多的台北縣，平均漲幅有六至八％，台北市每坪成交單價是三○‧四萬，約較上月上揚三％。\\u3000\\u3000信義房屋不動產企研室主任蘇啟榮表示，市場買氣在一月十二日立委選後明顯啟動。\\u3000\\u3000當時選後市場對於兩岸開放的預期心態明顯轉濃，房市長期價量走勢被看好；再加上國際原物料價格不斷上漲，鋼筋、水泥等建材等原物料價格也漲聲不斷。擔心房價看回不回及存款被通膨吃掉的心態下，民眾購屋保值意願轉強。\\u3000\\u3000永慶房屋表示，二月份通常是屬於年節的淡季時節，因為剛過完農曆年、民眾不會急著看房子，但根據永慶內部統計資料卻發現，二月大台北地區的平均成交單價為三○‧四萬元，較上月上揚三％，成交件數則因春節長假交易天數減少影響而較上月下滑，但若以實際工作天數來計算，則較上月成長一成。\\u3000\\u3000蘇啟榮說，這陣子店面人員都明顯感覺到買氣有回升，二月份的成屋市場，也在年後消息轉好下，成交量與一月相比，回升兩成，房價變動方面，二月份在北縣及高雄市的房價走升的帶動下，全台主要都會區房價微幅上揚一個百分點，呈現高檔持平的態勢。\\u3000\\u3000蘇啟榮指出，在板橋的電梯大樓，有三成買盤是來自台北市，北縣的房價，也被台北市的買主慢慢買起來，跟上個月相比，一坪約有六至八％的漲幅。\\u3000\\u3000在高雄部分，主要則是受到高價產品成交比重拉高所致，且高雄有捷運通車、三通話題帶動，讓捷運周邊房市成為買方指名度較高的區域，中信房屋也表示，在二月，高雄的房屋成交量，位居全省成交量之冠。\\u3000\\u3000尤其農十六特區及高雄巨蛋商圈周邊生活機能及都市景觀較佳，舉凡大樓、店面及透天產品都頗受青睞。在這些區域高價住宅交易增加之下，大幅推升高雄市二月份的平均房價。\\n                \\n                \\n\\n\\n    \\n',\n",
       " '2008/03/26- [工商/財經政策白皮書／南北平衡篇/A6版] \\n\\n\\n投資下鄉 平衡南北\\n\\n\\n                【呂雪彗】\\u3000\\u3000台北市信義區一坪均價一二○萬元的豪宅，推出後，短短月餘就銷售一空；但愈往台灣南部走，房價落差愈大，屏東市區的房價，近五年來波動不大，平均一坪只賣七到十萬元，還乏人問津。南北房價差異如此之大，反映的是南、北發展不平衡。\\u3000\\u3000南北所得 相差懸殊\\u3000\\u3000北市一個家庭的年所得，比嘉義、高雄縣高上近一倍。\\u3000\\u3000根據主計處的統計，台北市一個家庭的總所得幾乎比嘉義、高雄縣高出一倍。台北市的家庭在繳稅之後的可支配所得，一年平均是一二六萬元，高雄縣只有六八萬元，換句話說，高雄縣家庭用在消費、儲蓄、生養子女、一切食衣住行等生活上所需花用的錢，僅佔台北市家庭的五四％。\\u3000\\u3000以教育程度情況來看，具高中以上學歷者，在台北市的人口比重高達八三％，雲林縣、嘉義、屏東僅四三至四七％；也就是說一百人當中，不到五十個人受過高中以上的教育。\\u3000\\u3000難道北部人比較聰明，比較會賺錢？「這是政府早年資源集中北部的結果」，台大經濟系教授陳博志說，政府決定發展電子產業，設立竹科開始，教育及研發資源就都往北部傾斜，帶來就學及就業人口往北部移動，北部與南部房價因此愈拉愈遠。\\u3000\\u3000「為啥米政府卡照顧台北人？」這是南部人心中的問號。南北差距若不趕緊解決，前經濟部次長尹啟銘憂心「由南北失衡，轉為南北對立，恐怕將萬劫不復！」\\u3000\\u3000中南部長期經濟不景氣，已逐漸形成南北對立，這種危機古今中外都有。美國南北戰爭發生的原因，其實是工商發達的北部與農業為主的南部，因為經濟力的落差而產生的衝突。\\u3000\\u3000民進黨雖看出南北失衡問題，也想分散資源到南部，但由於缺乏策略性思考，八年下來，改變不大，新政府上任要如何才能縮短差距？\\u3000\\u3000陳博志認為須要有大計畫往中南部投資，產生群聚效應，才能逐步縮短南北落差。前經濟部次長尹啟銘也以竹科成功塑造產業群聚區位規劃為例「不是有了大片土地，設置工業區、產業園區，給予○○六六八八優惠，就能吸引產業進駐，唯有配合各地資源特性，生活機能、休閒設施等完整策略佈局，才能把人才留在當地」。\\u3000\\u3000「南北差距根本癥結在產業！」雖然中南部縣市寄望藉由高鐵通車後，可縮短南北差距，不過尹啟銘認為，高鐵通車只是開啟一扇門「如果只有交通基礎建設，沒有生活圈完整配套，就會像屏東生技園區、故宮南院一樣，空有硬體建設，缺乏人才及產業群聚，資源可能丟錯地方」。\\u3000\\u3000嘉義立委翁重鈞就說，八輕移走後，嘉義縣幾乎沒有重大投資進駐「天天都有一堆選民要求找工作」，一定要設立工業區、科學園區，才能使地方繁榮。\\u3000\\u3000花蓮立委傅崑萁也說，蘇花高遲未拍板，花蓮遠來飯店第二期擴建一五○億元投資已決定喊卡，完工三年的鳳林科技園區也因交通不便，形同荒地。\\u3000\\u3000產業南移 才是解藥\\u3000\\u3000專家表示，要設立工業區、產業園區，才能使地方繁榮。\\u3000\\u3000各地民代都希望為地方爭取高速公路、科學園區和工業區，但這些真能縮短南北差距？尹啟銘不這麼認為，他說，像雲林以南其實可以塑造為「農業創新黃金走廊」，也就是在傳統農業注入高科技新元素，改造南部新興產業結構。\\u3000\\u3000屏東縣九如鄉長許重慶也認為，中南部人口有很大比例是農民，這些人窮其一生在土壤上實作，而換來的農業技術，其實在國際之上，要縮短南北差距，一定要設法先安定這一塊，讓農民靠農技專業就能生活，不需要將勞力降價釋出打零工，搶奪基層勞工飯碗。\\u3000\\u3000至於真正的勞工，許重慶說這些人較易進行職業訓練，若能提供誘因，給予電腦和語言等在職訓練，就能逐步從工廠最底層往上提升，更符合產業需要。「只要新政府有心，多聽在地人意見，有起步就會有進步」。\\n                \\n                \\n\\n\\n    \\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#舉例：取dictionary的方式\n",
    "#key是\"yyyy-mm\"，value是一個list，是包含了該月所有的新聞。list裡是str\n",
    "text_dict['2008-03'][0:2] #看兩篇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將每個月的情緒指數找出來\n",
    "\n",
    "### Note: `text_dict{}` 是我們所有新聞的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將overall dict的sentiment index找出來，存成一個dictionary\n",
    "sentimentIndex = {}\n",
    "#年月份是key name，其對應的value是list\n",
    "for yyyymm in text_dict:\n",
    "    tempIndex = []\n",
    "    for i in range(0, len(text_dict[yyyymm])):\n",
    "        tempIndex.append(get_sentiment(text_dict[yyyymm][i]))\n",
    "    sentimentIndex[yyyymm] = tempIndex\n",
    "\n",
    "#計算月平均\n",
    "avg_senti = {} #每月平均情緒指數 的字典\n",
    "for key in sentimentIndex:\n",
    "    avg_senti[key] = sum(sentimentIndex[key])/len(sentimentIndex[key])\n",
    "average_sentiment = pd.DataFrame(avg_senti, index = ['sentiment_index'])\n",
    "average_sentiment = average_sentiment.transpose()\n",
    "average_sentiment = average_sentiment.sort_index(axis = 0)\n",
    "average_sentiment.to_csv(\"average_sentiment_without_negation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Approach\n",
    "\n",
    "考慮情緒字前後相鄰的三個字，如果有包含：「不、非」等否定字，則將情緒指標值加負號"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新定義`get_sentiment()`\n",
    "\n",
    "遇到negation（否定詞）則符號反轉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words\n",
    "f = open(\"NTUSD/stopwords_ch.txt\", \"r\")\n",
    "stop_words = f.read().splitlines()\n",
    "\n",
    "#判斷否定\n",
    "negation = [\"不\",\"非\",\"不是\",\"並非\"]\n",
    "\n",
    "#Def\n",
    "\n",
    "#句子到詞彙：sentence to word\n",
    "def sent2word(sentence,stop_words=stop_words):\n",
    "    words = jieba.cut(sentence, HMM=False)\n",
    "    words = [w for w in words if w not in stop_words] #不在停用字當中的才留下 i.e.去掉無意義的短小字\n",
    "    return words\n",
    "\n",
    "def get_sentiment(sent):\n",
    "    tokens = sent2word(sent)\n",
    "    score = 0\n",
    "    countword = 0\n",
    "    for w in tokens:\n",
    "        if w in sentiment_dict.keys():\n",
    "            score += sentiment_dict[w]\n",
    "            countword += 1\n",
    "        #如果前後三個字的範圍是否定字\n",
    "        nearby_ind = [tokens.index(w)+i for i in [1,2,3,-1,-2,-3]]\n",
    "        for ind in nearby_ind:\n",
    "            try:\n",
    "                if tokens[ind] in negation:\n",
    "                    score = -score\n",
    "                    #print(tokens[ind])\n",
    "                #print(tokens[ind], end = \" \")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if countword != 0:\n",
    "        return score/countword\n",
    "    else:\n",
    "        return 0\n",
    "##每則新聞的情緒指數按照「情緒字出現的頻率」除以「該則新聞的詞彙數」得到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1794871794871795"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "testtext = \"香港股市新春一開盤即呈現上揚，於周二因大型藍籌股賣壓較重，加上不確定美國是否降息，投資人退場觀望，恆生指數跌破16,000點關卡。周三至周四，在美國聯邦準備理事會如預期降息2碼的利多下，地產與金融類股全面上揚，指數收復1萬6000點關卡，周五收於16,071.29點，一周上漲27.08 點，漲幅為0.17%。在類股方面，地產類股受惠於降息利多，年初以來全面走揚，加上港府表示，今年公共住宅建設將減少三分之一，可望刺激香港私人住宅市場，但由於利多因素先前已反應在股價上，恆生地產類股於上周小幅下跌0.63%。銀行類股亦為受惠於降息受惠的類股之一，上周上揚0.4%。自本周開始為銀行類股公布業績季節，預計結果會高於市場預期。利率敏感性低的公共事業類股上周上漲3.5%，通訊類股則下跌0.05%。年初至今，在投資人預期心理搶進利率敏感性類股下，香港恆生指數從15,000點一路攀升至16,000點，這波上漲動力來自於地產與金融類股。但短期內，地產與金融類股漲幅已大，預期在股價輪動效應下，資金會逐漸轉向有實質盈餘成長，投資法人持股比重較低，股價處於起漲階段的中資概念股，以及股價表現仍處落後的通訊類股。JP摩根分析師認為，今年8月份之前，美國利率仍有5碼的非下調空間，年底時聯邦基金利率會下調至4.25%，與美股連動性高的香港恆生指數未來有上探18,500 點的潛力。\"\n",
    "get_sentiment(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將overall dict的sentiment index找出來，存成一個dictionary\n",
    "sentimentIndex = {}\n",
    "#年月份是key name，其對應的value是list\n",
    "for yyyymm in text_dict:\n",
    "    tempIndex = []\n",
    "    for i in range(0, len(text_dict[yyyymm])):\n",
    "        tempIndex.append(get_sentiment(text_dict[yyyymm][i]))\n",
    "    sentimentIndex[yyyymm] = tempIndex\n",
    "    \n",
    "avg_senti = {} #每月平均情緒指數 的字典\n",
    "for key in sentimentIndex:\n",
    "    avg_senti[key] = sum(sentimentIndex[key])/len(sentimentIndex[key])\n",
    "\n",
    "average_sentiment = pd.DataFrame(avg_senti, index = ['sentiment_index'])\n",
    "average_sentiment = average_sentiment.transpose()\n",
    "#average_sentiment.to_csv(\"average_sentiment.csv\")\n",
    "average_sentiment = average_sentiment.sort_index(axis = 0)\n",
    "average_sentiment.to_csv(\"average_sentiment_with_negation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

[Files]
embedding_file = ./dataset/vectors.50d.txt
# embedding files, trained by GloVe
train_file = ./dataset/data.train
# input file for training, one sample per line
test_file = ./dataset/data.test
# input file for testing, one sample per line
dev_file = ./dataset/data.dev
# input file for development, one sample per line
save_each = ./h5/UTCNN_itr{epoch:02d}.h5
# saved filename of each iteration
save_final = ./h5/UTCNN_best.h5
# saved fileanme for the final iteration
save_pickle = ./pickle/predict.pickle
# saved fileanme for the prediiction, saved in pickle format

[Pars]
v_dim = 50
# dimension in the word embedding file
u_dim = 10
# dimension of the user vector embeddings
mini_u_dim = 5
# first dimension of the user matrix embeddings
t_dim = 10
# dimension of the topic vector embeddings
mini_t_dim = 5
# first dimension of the topic matrix embeddings
con_size = 50
# number of the convolution channels
l_size = 3
# number of labels
max_topic = 3
# maximum number of topics per sample
flength1 = 1
# window size in the first convolution filter
flength2 = 2
# window size in the second convolution filter
flength3 = 3
# window size in the third convolution filter
rnd_base = 0.01
# random base of the initial vector, in the range of [-rndBase, rndBase]
lr = 0.03
# learning rate
batch_size = 10
# batch size per training
patience = 3
# number of patience waiting for best pars
max_epoch = 10
# maximum number of iteration
